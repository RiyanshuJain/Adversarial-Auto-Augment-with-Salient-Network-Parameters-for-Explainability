# Adversarial-Auto-Augment-with-Salient-Network-Parameters-for-Explainability
This project proposes a solution to two problems in image classification: data augmentation and model explainability. The first part of the proposal suggests a domain-agnostic but task-informed data augmentation method that uses intermediate layer representations of the end-task model for augmentation, without relying on any domain knowledge. This method generates a distant ”hard positive example” while preserving the original label. The second part of the proposal suggests using parameter saliency maps for model explainability instead of conventional saliency maps that focus on locating input regions in an image to which the network’s output is sensitive. The proposed algorithm identifies and analyzes the network parameters responsible for erroneous decisions, providing a better interpretable understanding of model behaviors. The proposed approach is evaluated on CIFAR100 dataset using ResNet18 classifier. The evaluation includes visualizing augmentations generated by different techniques and comparing them with ground truth labels. The performance on noisy datasets is also assessed to check the robustness of the proposed algorithm.

### To run the LPA3 algorithm - first insatll the dependencies using - pip install wandb
---> cd LPA3/PES

Run on terminal - 

--> python3 PES_LPA3.py --dataset cifar100 --data_path ../data/  --noise_rate 0.9 --lambda_u 100

--> python3 PES_LPA3.py --dataset cifar100 --data_path ../data/  --noise_rate 0.8 --lambda_u 100

### To run the parameter-space-saliency -

---> cd parameter-space-saliency

Run on terminal - 

--> python3 parameter_and_input_saliency.py --image_path raw_images/19.jpg --image_target_label 19

--> python3 parameter_and_input_saliency.py --image_path raw_images/92.jpg --image_target_label 92
