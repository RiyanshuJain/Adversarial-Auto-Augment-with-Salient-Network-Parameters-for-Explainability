# Adversarial-Auto-Augment-with-Salient-Network-Parameters-for-Explainability
This project proposes a solution to two problems in image classification: data augmentation and model explainability. The first part of the proposal suggests a domain-agnostic but task-informed data augmentation method that uses intermediate layer representations of the end-task model for augmentation, without relying on any domain knowledge. This method generates a distant ”hard positive example” while preserving the original label. The second part of the proposal suggests using parameter saliency maps for model explainability instead of conventional saliency maps that focus on locating input regions in an image to which the network’s output is sensitive. The proposed algorithm identifies and analyzes the network parameters responsible for erroneous decisions, providing a better interpretable understanding of model behaviors. The proposed approach is evaluated on CIFAR100 dataset using ResNet18 classifier. The evaluation includes visualizing augmentations generated by different techniques and comparing them with ground truth labels. The performance on noisy datasets is also assessed to check the robustness of the proposed algorithm.
